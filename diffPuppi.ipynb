{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.conv import GraphConv, EdgeConv, GCNConv\n",
    "\n",
    "from torch_cluster import radius_graph, knn_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMETNetwork(nn.Module):\n",
    "    def __init__ (self, continuous_dim, cat_dim, output_dim=1, hidden_dim=32, conv_depth=1):\n",
    "        super(GraphMETNetwork, self).__init__()\n",
    "        \n",
    "        self.embed_continuous = nn.Sequential(nn.Linear(continuous_dim,hidden_dim),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Linear(hidden_dim, hidden_dim),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Linear(hidden_dim, hidden_dim),\n",
    "                                             # nn.BatchNorm1d(hidden_dim) # uncomment if it starts overtraining\n",
    "                                            )\n",
    "\n",
    "        self.embed_categorical = nn.Sequential(nn.Linear(cat_dim,hidden_dim),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(hidden_dim, hidden_dim),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(hidden_dim, hidden_dim),\n",
    "                                               # nn.BatchNorm1d(hidden_dim)\n",
    "                                              )\n",
    "\n",
    "        self.conv_continuous = nn.ModuleList()        \n",
    "        for i in range(conv_depth):\n",
    "            mesg = nn.Sequential(nn.Linear(2*hidden_dim, 3*hidden_dim//2),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(3*hidden_dim//2, hidden_dim),\n",
    "                                 # nn.BatchNorm1d(hidden_dim)\n",
    "                                )\n",
    "\n",
    "            self.conv_continuous.append(\n",
    "                EdgeConv(nn=mesg).jittable()\n",
    "                #GCNConv(hidden_dim, hidden_dim).jittable()\n",
    "            )\n",
    "            \n",
    "        self.conv_categorical = nn.ModuleList()        \n",
    "        for i in range(conv_depth):\n",
    "            mesg = nn.Sequential(nn.Linear(2*hidden_dim, 3*hidden_dim//2),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(3*hidden_dim//2, hidden_dim),\n",
    "                                 # nn.BatchNorm1d(hidden_dim)\n",
    "                                )\n",
    "            self.conv_categorical.append(\n",
    "                EdgeConv(nn=mesg).jittable()\n",
    "                #GCNConv(hidden_dim, hidden_dim).jittable()\n",
    "            )\n",
    "        \n",
    "        self.output = nn.Sequential(nn.Linear(2*hidden_dim, hidden_dim),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim//2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim//2, output_dim)\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x_cont, x_cat, edge_index, batch):\n",
    "        emb_cont = self.embed_continuous(x_cont)\n",
    "        emb_cat = self.embed_categorical(x_cat)\n",
    "        \n",
    "        # graph convolution for continuous variables\n",
    "        for co_conv in self.conv_continuous:\n",
    "            emb_cont = co_conv(emb_cont, edge_index)\n",
    "\n",
    "        # graph convolution for discrete variables\n",
    "        for ca_conv in self.conv_categorical:\n",
    "            emb_cat = ca_conv(emb_cat, edge_index)\n",
    "                              \n",
    "        # concatenate embeddings together to make description of weight inputs\n",
    "        emb = torch.cat([emb_cont,emb_cat], dim=1)\n",
    "        \n",
    "        out = self.output(emb)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class GraphMET(nn.Module):\n",
    "    def __init__(self, continuous_dim, categorical_dim):\n",
    "        super(GraphMET, self).__init__()\n",
    "        self.graphnet = GraphMETNetwork(continuous_dim, categorical_dim,\n",
    "                                        output_dim=1, hidden_dim=32,\n",
    "                                        conv_depth=1)\n",
    "    \n",
    "    def forward(self, x_cont, x_cat, edge_index, batch):\n",
    "        weights = self.graphnet(x_cont, x_cat, edge_index, batch)\n",
    "        return torch.sigmoid(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import (Data, Dataset)\n",
    "import glob\n",
    "import os.path as osp\n",
    "\n",
    "# dummy dataloader since I don't have the npz\n",
    "class METDataset(Dataset):\n",
    "    \"\"\"PyTorch geometric dataset from processed hit information\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        super(METDataset, self).__init__(root)\n",
    "    \n",
    "    def download(self):\n",
    "        pass #download from xrootd or something later\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        if not hasattr(self,'input_files'):\n",
    "            self.input_files = glob.glob(self.processed_dir+'/*.pt')\n",
    "        return [f.split('/')[-1] for f in self.input_files]\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        if not hasattr(self,'processed_files'):\n",
    "            self.processed_files = self.input_files\n",
    "        return self.processed_files\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = torch.load(self.processed_files[idx])\n",
    "        return data\n",
    "    \n",
    "    def process(self):\n",
    "        pass\n",
    "\n",
    "dataset = METDataset(root='/home/lagray/graphmet/data')\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "train_data = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.script(GraphMET(7, 3)).to('cuda') # [px, py, pt, eta, d0, dz, mass], [pdgid, charge, fromPV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "def f_loss(weights, px, py, true_px, true_py):\n",
    "    return 0.5*( ( (weights*px).sum() + true_px)**2 + ( (weights*py).sum() + true_py)**2 )\n",
    "\n",
    "deltaR = 0.4\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "for e in range(0, 100):\n",
    "    avg_loss = 0\n",
    "    for data in train_data:\n",
    "        if isinstance(data, Data):\n",
    "            opt.zero_grad()\n",
    "            data.to('cuda')\n",
    "            x_cont = data.x[:,:7]\n",
    "            x_cat = data.x[:,8:]\n",
    "        \n",
    "            phi = torch.atan2(data.x[:,1], data.x[:,0])\n",
    "            etaphi = torch.cat([data.x[:,3][:,None], phi[:,None]], dim=1)        \n",
    "        \n",
    "            # NB: there is a problem right now for comparing hits at the +/- pi boundary\n",
    "            edge_index = radius_graph(etaphi, r=deltaR, batch=data.batch, loop=True, max_num_neighbors=255)\n",
    "        \n",
    "            out = model(x_cont, x_cat, edge_index, data.batch)\n",
    "        \n",
    "            true_MET = data.y[:,0]\n",
    "            true_METphi = data.y[:,1]\n",
    "            loss = f_loss(out, data.x[:,0], data.x[:,1], true_MET*torch.cos(true_METphi), true_MET*torch.sin(true_METphi))\n",
    "        \n",
    "            loss.backward()\n",
    "            avg_loss += loss.item()\n",
    "            opt.step()\n",
    "    print(avg_loss, len(train_data))\n",
    "    print(e, ':',avg_loss/len(train_data))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
